/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/nibabel/optpkg.py:101: UserWarning: A NumPy version >=1.22.4 and <1.29.0 is required for this version of SciPy (detected version 1.22.3)
  pkg = __import__(name, fromlist=fromlist)
[rank: 0] Seed set to 42
Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
wandb: Currently logged in as: felix-rong (tdt4265-group187). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.16.5
wandb: Run data is saved locally in ./wandb/run-20240328_133100-ifvjex97
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ASOCA_idun
wandb: â­ï¸ View project at https://wandb.ai/tdt4265-group187/ASOCA
wandb: ðŸš€ View run at https://wandb.ai/tdt4265-group187/ASOCA/runs/ifvjex97/workspace
/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.
  warn_deprecated(argname, msg, warning_category)
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name    | Type          | Params
------------------------------------------
0 | model   | UNet          | 4.8 M 
1 | loss_fn | DiceFocalLoss | 0     
------------------------------------------
4.8 M     Trainable params
0         Non-trainable params
4.8 M     Total params
19.232    Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
Traceback (most recent call last):
  File "/cluster/work/felixzr/TDT4265_StarterCode_2024/pytorch-lightning-template/trainer_own.py", line 141, in <module>
    trainer.fit(model, datamodule=dm)
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1033, in _run_stage
    self.fit_loop.run()
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 140, in run
    self.advance(data_fetcher)
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 250, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 190, in run
    self._optimizer_step(batch_idx, closure)
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 268, in _optimizer_step
    call._call_lightning_module_hook(
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/lightning/pytorch/core/module.py", line 1303, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py", line 152, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/amp.py", line 80, in optimizer_step
    closure_result = closure()
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 144, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 129, in closure
    step_output = self._step_fn()
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 318, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 309, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
  File "/cluster/work/felixzr/TDT4265_StarterCode_2024/pytorch-lightning-template/trainer_own.py", line 68, in training_step
    loss = self.loss_fn(y_hat, y)
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/monai/losses/dice.py", line 917, in forward
    focal_loss = self.focal(input, target)
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/monai/losses/focal_loss.py", line 163, in forward
    loss = sigmoid_focal_loss(input, target, self.gamma, self.alpha)
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/monai/losses/focal_loss.py", line 238, in sigmoid_focal_loss
    loss: torch.Tensor = input - input * target + max_val + ((-max_val).exp() + (-input - max_val).exp()).log()
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/monai/data/meta_tensor.py", line 282, in __torch_function__
    ret = super().__torch_function__(func, types, args, kwargs)
  File "/cluster/home/felixzr/.conda/envs/tdt4265/lib/python3.10/site-packages/torch/_tensor.py", line 1386, in __torch_function__
    ret = func(*args, **kwargs)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 896.00 MiB. GPU 0 has a total capacty of 39.39 GiB of which 219.25 MiB is free. Process 31865 has 13.20 GiB memory in use. Including non-PyTorch memory, this process has 25.95 GiB memory in use. Of the allocated memory 23.97 GiB is allocated by PyTorch, and 1.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
wandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.011 MB of 0.022 MB uploaded (0.003 MB deduped)wandb: - 0.014 MB of 0.022 MB uploaded (0.003 MB deduped)wandb: \ 0.022 MB of 0.022 MB uploaded (0.003 MB deduped)wandb: ðŸš€ View run ASOCA_idun at: https://wandb.ai/tdt4265-group187/ASOCA/runs/ifvjex97/workspace
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240328_133100-ifvjex97/logs
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Sanity Checking DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00,  0.06it/s]                                                                           Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/4 [00:00<?, ?it/s] srun: error: idun-06-16: task 0: Exited with exit code 1
