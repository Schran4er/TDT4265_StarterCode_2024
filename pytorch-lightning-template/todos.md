Task 2: Medical Image Segmentation

Cybele lab hours:
Mondays 15:15 - 17:00 and
Thursdays 12:00 - 14:00


Morgen:
wie ist tutorial Stand? 
    https://www.youtube.com/watch?v=8ZCWLC3xI_Q
    https://docs.monai.io/en/stable/ (getting started)
    https://github.com/Project-MONAI/tutorials (3d segmentation)
    https://github.com/Project-MONAI/tutorials/blob/main/3d_segmentation/spleen_segmentation_3d.ipynb


zuerst simple architektur 
    -> refinement
    - ✅ test cuda in notebook on idun, login node? gpu node? interactive slurm job? https://www.hpc.ntnu.no/idun/

Todos:
- code und ordner aufräumen!!
- preprocessing schreiben! (felix)
- Do we need to detect/classify between normal/diseased or just segmentate them all

Plan:
 - Data exploration: nrrd, vtp, stl data ✅
        Diseased/Normal
        ├── Annotations --> images segmentated by the 3 experts manually -> ground truth!
        ├── CTCA --> whole scans (2D) / raw data! goal: detect aorta, generate 3d (centerline & surfacemeshes), classify normal/diseased
        ├── Centerlines --> centerlines of aortas
        ├── SurfaceMeshes --> aorta surfaces
        └── Testset_Disease/Testset_Normal -> useless because not labelled

- see MONAI ✅

- Pre-processing pipeline:
    - keep in mind that different .nrrd files may have differenz z-dimension -> SpacingD correct pixdim ✅
    -> divide into training/test/val (because testset doesn't have labels) -> Felix
    -> ✅ set random seed (in monai) for comparable results
    -> Data augmentation: crop/rotate/flip/... (look at previous task (assignement 3))
    - Convert data to usable format for a ML model:
        - use 3D augmentation (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9952534/ "Comparing 3D, 2.5D, and 2D Approaches to Brain Image Auto-Segmentation")

    - image contrast normalization to zero mean and unit variance (ASOCA paper submission 2)
    - Frangi/... filters not/? used (as ASOCA paper states that they are too computationally expensive)


- build baseline model
    - Look for pre trained model for medical image segmentation (from literature) which has not been trained on the asoca dataset!!
- build training setup!!
    - loss function: Soft Dice loss + Cross entropy loss or focal loss (tensorboard for keeping track of the loss?)
    - performance metrics
    - optimizer
    - regularization
    - early stopping
    - pre training (take pre trained model, adjust it, train on our data)
    - speed up training with batch normalization

- post-processsing: remove small disconnected components

- do improvements
    - note and justify/explain the import changes!!
- do the same with another architecture

- ensure that we only train on ONE gpu (-> TA session)

- runtime analysis
    - runtime = inference time: how fast can the model detect? (in real application)
- carbon footprint analysis
 - total training time * GPU_power = work -> convert to how far we can drive with a tesla


Documentation:
- Visualization: show annotation and AI segmentation result
- Readme for code (how to train, use the model etc., conda env)
- Technical documentation
- Presentation


Further work:
- other filters (check also other submissions from ASOCA paper)
- further post-processing magic (check also other submissions from ASOCA paper)



Dataset infos (nrrd):
     1 NRRD0005         -> NRRD version 5
     2 # This NRRD file was generated by pynrrd
     3 # on 2020-08-13 06:54:10(GMT).
     4 # Complete NRRD file format specification at:
     5 # http://teem.sourceforge.net/nrrd/format.html
     6 type: int32
     7 dimension: 3     -> 3 dims (up to 16 possible)
     8 space: left-posterior-superior       --> orientation of the nrrd grid relative to the surrounding space, e.g. patient. "left-posterior-superior" or "LPS":  For medical data, a patient-based right-handed coordinate frame, with ordered basis vectors pointing towards left, posterior, and superior, respectively. This space is used in DICOM 3.
     9 sizes: 512 512 224  -> number of samples along each dimension
    10 space directions: (0.37890600000000008,0,0) (0,0.37890600000000008,0) (0,0,0.62500000000000011)  -> axis directions in global coordinates
    11 kinds: domain domain domain
    12 endian: little
    13 encoding: gzip
    14 space origin: (-88.300003051757855,-128.80000305175787,-244.37500000000014)      -> global coordinates of first voxel


Mittwoch:
    - Preprocessing Grundmodell
    - Refactoring
    - fix Accuracy (-> look at inference output?)
    - Read into UNet:
        architecture with randomly initialized weights
        - related work research: pick a model (with random weights) as baseline, then the same but pretrained, then try different loss/acc functions

Donnerstag:
    - Modell mit vollständigem Datensatz laufen lassen:
        wenn gut: dann ist das baseline
            -> investigate data augmentation & postprocessing
        wenn schlecht: Übungsstunde
    - refactor -> getan
    - implement pretrained model

bis zur Übungsstunde:
    - Felix: Pre- & Postprocessing
    - Alex: pretrained model zum laufen bringen